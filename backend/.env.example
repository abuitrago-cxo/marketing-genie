# GEMINI_API_KEY=

# Ollama Configuration (Optional - uncomment and set to use Ollama)
# OLLAMA_API_BASE_URL="http://localhost:11434" # Or http://ollama:11434 if running backend outside docker-compose but ollama in docker
# OLLAMA_QUERY_GENERATOR_MODEL="llama3"
# OLLAMA_REFLECTION_MODEL="llama3"
# OLLAMA_ANSWER_MODEL="llama3"
