---
description: 
globs: 
alwaysApply: false
---
æ ¹æ®æ‚¨æä¾›çš„è±†åŒ…APIæ–‡æ¡£å’Œæˆ‘ä¹‹å‰çš„åˆ†æï¼Œä»¥ä¸‹æ˜¯å°†é¡¹ç›®ä»Gemini APIæ›¿æ¢ä¸ºè±†åŒ…APIçš„è¯¦ç»†æ­¥éª¤ï¼š

## 1. ä¿®æ”¹ä¾èµ–é¡¹

[project]
name = "agent"
version = "0.0.1"
description = "Backend for the LangGraph agent"
authors = [
    { name = "Philipp Schmid", email = "schmidphilipp1995@gmail.com" },
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.11,<4.0"
dependencies = [
    "langgraph>=0.2.6",
    "langchain>=0.3.19",
    # ç§»é™¤ langchain-google-genaiï¼Œæ·»åŠ è±†åŒ…SDK
    # "langchain-google-genai",
    "volcengine-python-sdk[ark]>=1.0.0",
    "python-dotenv>=1.0.1",
    "langgraph-sdk>=0.1.57",
    "langgraph-cli",
    "langgraph-api",
    "fastapi",
    # ç§»é™¤ google-genai
    # "google-genai",
]

[project.optional-dependencies]
dev = ["mypy>=1.11.1", "ruff>=0.6.1"]

[build-system]
requires = ["setuptools>=73.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.ruff]
lint.select = [
    "E",    # pycodestyle
    "F",    # pyflakes
    "I",    # isort
    "D",    # pydocstyle
    "D401", # First line should be in imperative mood
    "T201",
    "UP",
]
lint.ignore = [
    "UP006",
    "UP007",
    # We actually do want to import from typing_extensions
    "UP035",
    # Relax the convention by _not_ requiring documentation for every function parameter.
    "D417",
    "E501",
]
[tool.ruff.lint.per-file-ignores]
"tests/*" = ["D", "UP"]
[tool.ruff.lint.pydocstyle]
convention = "google"

[dependency-groups]
dev = [
    "langgraph-cli[inmem]>=0.1.71",
    "pytest>=8.3.5",
]

## 2. ä¿®æ”¹é…ç½®æ–‡ä»¶

import os
from pydantic import BaseModel, Field
from typing import Any, Optional

from langchain_core.runnables import RunnableConfig


class Configuration(BaseModel):
    """The configuration for the agent."""

    # æŸ¥è¯¢ç”Ÿæˆæ¨¡å‹ - ä½¿ç”¨å¸¸è§„æ¨¡å‹ï¼Œæ³¨é‡é€Ÿåº¦
    query_generator_model: str = Field(
        default="doubao-pro-256k-241115",
        metadata={
            "description": "The name of the language model to use for the agent's query generation."
        },
    )

    # åæ€æ¨¡å‹ - ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹ï¼Œæ³¨é‡æ¨ç†è´¨é‡
    reflection_model: str = Field(
        default="doubao-1.5-thinking-pro-250415",
        metadata={
            "description": "The name of the language model to use for the agent's reflection."
        },
    )

    # ç­”æ¡ˆç”Ÿæˆæ¨¡å‹ - ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹ï¼Œæ³¨é‡æœ€ç»ˆè´¨é‡
    answer_model: str = Field(
        default="doubao-1.5-thinking-pro-250415",
        metadata={
            "description": "The name of the language model to use for the agent's answer."
        },
    )

    # ç½‘ç»œæœç´¢æ¨¡å‹ - ä½¿ç”¨å¸¸è§„æ¨¡å‹ï¼Œæ³¨é‡ä¿¡æ¯æå–é€Ÿåº¦
    web_research_model: str = Field(
        default="doubao-pro-256k-241115",
        metadata={
            "description": "The name of the language model to use for web research."
        },
    )

    number_of_initial_queries: int = Field(
        default=3,
        metadata={"description": "The number of initial search queries to generate."},
    )

    max_research_loops: int = Field(
        default=2,
        metadata={"description": "The maximum number of research loops to perform."},
    )

    # æ·±åº¦æ€è€ƒæ¨¡å‹çš„è¶…æ—¶æ—¶é—´è®¾ç½®
    thinking_model_timeout: int = Field(
        default=1800,  # 30åˆ†é’Ÿ
        metadata={"description": "Timeout in seconds for thinking models."},
    )

    # å¸¸è§„æ¨¡å‹çš„è¶…æ—¶æ—¶é—´è®¾ç½®
    regular_model_timeout: int = Field(
        default=300,   # 5åˆ†é’Ÿ
        metadata={"description": "Timeout in seconds for regular models."},
    )

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> "Configuration":
        """Create a Configuration instance from a RunnableConfig."""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )

        # Get raw values from environment or config
        raw_values: dict[str, Any] = {
            name: os.environ.get(name.upper(), configurable.get(name))
            for name in cls.model_fields.keys()
        }

        # Filter out None values
        values = {k: v for k, v in raw_values.items() if v is not None}

        return cls(**values)

## 3. ä¿®æ”¹ä¸»è¦çš„å›¾å½¢æ–‡ä»¶

import os
import json

from agent.tools_and_schemas import SearchQueryList, Reflection
from dotenv import load_dotenv
from langchain_core.messages import AIMessage
from langgraph.types import Send
from langgraph.graph import StateGraph
from langgraph.graph import START, END
from langchain_core.runnables import RunnableConfig
# æ›¿æ¢ä¸ºè±†åŒ…SDK
from volcenginesdkarkruntime import Ark

from agent.state import (
    OverallState,
    QueryGenerationState,
    ReflectionState,
    WebSearchState,
)
from agent.configuration import Configuration
from agent.prompts import (
    get_current_date,
    query_writer_instructions,
    web_searcher_instructions,
    reflection_instructions,
    answer_instructions,
)
from agent.utils import (
    get_citations,
    get_research_topic,
    insert_citation_markers,
    resolve_urls,
)

load_dotenv()

# æ£€æŸ¥è±†åŒ…API Key
if os.getenv("ARK_API_KEY") is None:
    raise ValueError("ARK_API_KEY is not set")


def create_ark_client(timeout: int = 300) -> Ark:
    """åˆ›å»ºè±†åŒ…å®¢æˆ·ç«¯"""
    return Ark(
        api_key=os.getenv("ARK_API_KEY"),
        timeout=timeout,
    )


def call_doubao_model(model_name: str, messages: list, temperature: float = 0.0, 
                     structured_output_schema=None, timeout: int = 300):
    """
    è°ƒç”¨è±†åŒ…æ¨¡å‹çš„é€šç”¨å‡½æ•°
    
    Args:
        model_name: æ¨¡å‹åç§°
        messages: æ¶ˆæ¯åˆ—è¡¨
        temperature: æ¸©åº¦å‚æ•°
        structured_output_schema: ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
        timeout: è¶…æ—¶æ—¶é—´
    """
    client = create_ark_client(timeout=timeout)
    
    # æ ¼å¼åŒ–æ¶ˆæ¯
    if isinstance(messages, str):
        formatted_messages = [{"role": "user", "content": messages}]
    else:
        formatted_messages = messages
    
    # å¯¹äºæ·±åº¦æ€è€ƒæ¨¡å‹ï¼Œæ·»åŠ æ€è€ƒæç¤º
    if "thinking" in model_name and formatted_messages:
        # ç¡®ä¿æœ‰æ€è€ƒè¿‡ç¨‹è¾“å‡º
        original_content = formatted_messages[-1]["content"]
        formatted_messages[-1]["content"] = (
            "ä»»ä½•è¾“å‡ºéƒ½è¦æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œè¾“å‡ºå†…å®¹å¿…é¡»ä»¥ \"<think>\\n\\nå—¯\" å¼€å¤´ã€‚"
            "ä»”ç»†æ£æ‘©ç”¨æˆ·æ„å›¾ï¼Œåœ¨æ€è€ƒè¿‡ç¨‹ä¹‹åï¼Œæä¾›é€»è¾‘æ¸…æ™°ä¸”å†…å®¹å®Œæ•´çš„å›ç­”ã€‚\\n\\n"
            f"{original_content}"
        )
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=formatted_messages,
            temperature=temperature,
        )
        
        # å¤„ç†ç»“æ„åŒ–è¾“å‡º
        if structured_output_schema:
            content = response.choices[0].message.content
            # æå–æ€è€ƒå†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            reasoning_content = ""
            if hasattr(response.choices[0].message, 'reasoning_content'):
                reasoning_content = response.choices[0].message.reasoning_content
            
            # å°è¯•è§£æJSON
            try:
                # å¦‚æœå†…å®¹åŒ…å«æ€è€ƒè¿‡ç¨‹ï¼Œæå–å®é™…ç­”æ¡ˆéƒ¨åˆ†
                if content.startswith("<think>"):
                    # æ‰¾åˆ°æ€è€ƒè¿‡ç¨‹ç»“æŸçš„ä½ç½®
                    think_end = content.find("</think>")
                    if think_end != -1:
                        content = content[think_end + 8:].strip()
                
                # å°è¯•ä»å†…å®¹ä¸­æå–JSON
                json_start = content.find("{")
                json_end = content.rfind("}") + 1
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    parsed_data = json.loads(json_content)
                    return structured_output_schema(**parsed_data)
                else:
                    # å¦‚æœæ²¡æ‰¾åˆ°JSONï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹
                    parsed_data = json.loads(content)
                    return structured_output_schema(**parsed_data)
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                print(f"Failed to parse JSON from response: {content}")
                raise ValueError(f"Invalid JSON response: {content}")
        
        return response
        
    except Exception as e:
        print(f"Error calling Doubao model {model_name}: {e}")
        raise


# Nodes
def generate_query(state: OverallState, config: RunnableConfig) -> QueryGenerationState:
    """LangGraph node that generates a search queries based on the User's question."""
    configurable = Configuration.from_runnable_config(config)

    # check for custom initial search query count
    if state.get("initial_search_query_count") is None:
        state["initial_search_query_count"] = configurable.number_of_initial_queries

    # Format the prompt
    current_date = get_current_date()
    formatted_prompt = query_writer_instructions.format(
        current_date=current_date,
        research_topic=get_research_topic(state["messages"]),
        number_queries=state["initial_search_query_count"],
    )
    
    # ä½¿ç”¨å¸¸è§„æ¨¡å‹ç”ŸæˆæŸ¥è¯¢ï¼Œæ³¨é‡é€Ÿåº¦
    result = call_doubao_model(
        model_name=configurable.query_generator_model,
        messages=formatted_prompt,
        temperature=1.0,
        structured_output_schema=SearchQueryList,
        timeout=configurable.regular_model_timeout
    )
    
    return {"query_list": result.query}


def continue_to_web_research(state: QueryGenerationState):
    """LangGraph node that sends the search queries to the web research node."""
    return [
        Send("web_research", {"search_query": search_query, "id": int(idx)})
        for idx, search_query in enumerate(state["query_list"])
    ]


def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:
    """LangGraph node that performs web research using Google Search API."""
    configurable = Configuration.from_runnable_config(config)
    
    formatted_prompt = web_searcher_instructions.format(
        current_date=get_current_date(),
        research_topic=state["search_query"],
    )

    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®ç°å®é™…çš„æœç´¢åŠŸèƒ½
    # åŸä»£ç ä½¿ç”¨Google Search APIï¼Œæ‚¨éœ€è¦æ›¿æ¢ä¸ºæ‚¨çš„æœç´¢å®ç°
    # è¿™é‡Œæä¾›ä¸€ä¸ªåŸºç¡€æ¡†æ¶
    
    try:
        # ä½¿ç”¨å¸¸è§„æ¨¡å‹å¤„ç†æœç´¢ç»“æœï¼Œæ³¨é‡é€Ÿåº¦
        response = call_doubao_model(
            model_name=configurable.web_research_model,
            messages=formatted_prompt,
            temperature=0.0,
            timeout=configurable.regular_model_timeout
        )
        
        # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æœç´¢é€»è¾‘å’Œå¼•ç”¨å¤„ç†
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        search_result = response.choices[0].message.content
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„å¼•ç”¨æ•°æ®
        citations = [{
            "start_index": 0,
            "end_index": len(search_result),
            "segments": [{
                "label": f"Search Result {state['id']}",
                "short_url": f"https://example.com/result-{state['id']}",
                "value": f"https://example.com/full-result-{state['id']}"
            }]
        }]
        
        modified_text = insert_citation_markers(search_result, citations)
        sources_gathered = [item for citation in citations for item in citation["segments"]]

        return {
            "sources_gathered": sources_gathered,
            "search_query": [state["search_query"]],
            "web_research_result": [modified_text],
        }
    
    except Exception as e:
        print(f"Error in web research: {e}")
        # è¿”å›é”™è¯¯ä¿¡æ¯ä½œä¸ºæœç´¢ç»“æœ
        return {
            "sources_gathered": [],
            "search_query": [state["search_query"]],
            "web_research_result": [f"æœç´¢å‡ºé”™: {str(e)}"],
        }


def reflection(state: OverallState, config: RunnableConfig) -> ReflectionState:
    """LangGraph node that identifies knowledge gaps and generates potential follow-up queries."""
    configurable = Configuration.from_runnable_config(config)
    
    # Increment the research loop count
    state["research_loop_count"] = state.get("research_loop_count", 0) + 1

    # Format the prompt
    current_date = get_current_date()
    formatted_prompt = reflection_instructions.format(
        current_date=current_date,
        research_topic=get_research_topic(state["messages"]),
        summaries="\n\n---\n\n".join(state["web_research_result"]),
    )
    
    # ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹è¿›è¡Œåæ€ï¼Œæ³¨é‡æ¨ç†è´¨é‡
    result = call_doubao_model(
        model_name=configurable.reflection_model,
        messages=formatted_prompt,
        temperature=1.0,
        structured_output_schema=Reflection,
        timeout=configurable.thinking_model_timeout
    )

    return {
        "is_sufficient": result.is_sufficient,
        "knowledge_gap": result.knowledge_gap,
        "follow_up_queries": result.follow_up_queries,
        "research_loop_count": state["research_loop_count"],
        "number_of_ran_queries": len(state["search_query"]),
    }


def evaluate_research(
    state: ReflectionState,
    config: RunnableConfig,
) -> OverallState:
    """LangGraph routing function that determines the next step in the research flow."""
    configurable = Configuration.from_runnable_config(config)
    max_research_loops = (
        state.get("max_research_loops")
        if state.get("max_research_loops") is not None
        else configurable.max_research_loops
    )
    
    if state["is_sufficient"] or state["research_loop_count"] >= max_research_loops:
        return "finalize_answer"
    else:
        return [
            Send(
                "web_research",
                {
                    "search_query": follow_up_query,
                    "id": state["number_of_ran_queries"] + int(idx),
                },
            )
            for idx, follow_up_query in enumerate(state["follow_up_queries"])
        ]


def finalize_answer(state: OverallState, config: RunnableConfig):
    """LangGraph node that finalizes the research summary."""
    configurable = Configuration.from_runnable_config(config)

    # Format the prompt
    current_date = get_current_date()
    formatted_prompt = answer_instructions.format(
        current_date=current_date,
        research_topic=get_research_topic(state["messages"]),
        summaries="\n---\n\n".join(state["web_research_result"]),
    )

    # ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œæ³¨é‡è´¨é‡
    response = call_doubao_model(
        model_name=configurable.answer_model,
        messages=formatted_prompt,
        temperature=0.0,
        timeout=configurable.thinking_model_timeout
    )
    
    result_content = response.choices[0].message.content
    
    # æ‰“å°æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if hasattr(response.choices[0].message, 'reasoning_content'):
        print("=== æ€è€ƒè¿‡ç¨‹ ===")
        print(response.choices[0].message.reasoning_content)
        print("=== æ€è€ƒç»“æŸ ===")

    # å¤„ç†å¼•ç”¨æ›¿æ¢
    unique_sources = []
    for source in state["sources_gathered"]:
        if source["short_url"] in result_content:
            result_content = result_content.replace(
                source["short_url"], source["value"]
            )
            unique_sources.append(source)

    return {
        "messages": [AIMessage(content=result_content)],
        "sources_gathered": unique_sources,
    }


# Create our Agent Graph
builder = StateGraph(OverallState, config_schema=Configuration)

# Define the nodes we will cycle between
builder.add_node("generate_query", generate_query)
builder.add_node("web_research", web_research)
builder.add_node("reflection", reflection)
builder.add_node("finalize_answer", finalize_answer)

# Set the entrypoint as `generate_query`
builder.add_edge(START, "generate_query")
# Add conditional edge to continue with search queries in a parallel branch
builder.add_conditional_edges(
    "generate_query", continue_to_web_research, ["web_research"]
)
# Reflect on the web research
builder.add_edge("web_research", "reflection")
# Evaluate the research
builder.add_conditional_edges(
    "reflection", evaluate_research, ["web_research", "finalize_answer"]
)
# Finalize the answer
builder.add_edge("finalize_answer", END)

graph = builder.compile(name="pro-search-agent")

## 4. ä¿®æ”¹ç¯å¢ƒå˜é‡é…ç½®

# è±†åŒ…API Key - æ›¿æ¢åŸæ¥çš„GEMINI_API_KEY
ARK_API_KEY=

# å¯é€‰ï¼šæ¨¡å‹é…ç½®
# QUERY_GENERATOR_MODEL=doubao-pro-256k-241115
# REFLECTION_MODEL=doubao-1.5-thinking-pro-250415
# ANSWER_MODEL=doubao-1.5-thinking-pro-250415
# WEB_RESEARCH_MODEL=doubao-pro-256k-241115

# å¯é€‰ï¼šè¶…æ—¶æ—¶é—´é…ç½®ï¼ˆç§’ï¼‰
# THINKING_MODEL_TIMEOUT=1800
# REGULAR_MODEL_TIMEOUT=300

## 5. ä¿®æ”¹å‰ç«¯æ¨¡å‹é€‰æ‹©

import { useState } from "react";
import { Button } from "@/components/ui/button";
import { SquarePen, Brain, Send, StopCircle, Zap, Cpu } from "lucide-react";
import { Textarea } from "@/components/ui/textarea";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";

// Updated InputFormProps
interface InputFormProps {
  onSubmit: (inputValue: string, effort: string, model: string) => void;
  onCancel: () => void;
  isLoading: boolean;
  hasHistory: boolean;
}

export const InputForm: React.FC<InputFormProps> = ({
  onSubmit,
  onCancel,
  isLoading,
  hasHistory,
}) => {
  const [internalInputValue, setInternalInputValue] = useState("");
  const [effort, setEffort] = useState("medium");
  // é»˜è®¤ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹
  const [model, setModel] = useState("doubao-1.5-thinking-pro-250415");

  const handleInternalSubmit = (e?: React.FormEvent) => {
    if (e) e.preventDefault();
    if (!internalInputValue.trim()) return;
    onSubmit(internalInputValue, effort, model);
    setInternalInputValue("");
  };

  const handleInternalKeyDown = (
    e: React.KeyboardEvent<HTMLTextAreaElement>
  ) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleInternalSubmit();
    }
  };

  const isSubmitDisabled = !internalInputValue.trim() || isLoading;

  return (
    <form
      onSubmit={handleInternalSubmit}
      className={`flex flex-col gap-2 p-3 `}
    >
      <div
        className={`flex flex-row items-center justify-between text-white rounded-3xl rounded-bl-sm ${
          hasHistory ? "rounded-br-sm" : ""
        } break-words min-h-7 bg-neutral-700 px-4 pt-3 `}
      >
        <Textarea
          value={internalInputValue}
          onChange={(e) => setInternalInputValue(e.target.value)}
          onKeyDown={handleInternalKeyDown}
          placeholder="Who won the Euro 2024 and scored the most goals?"
          className={`w-full text-neutral-100 placeholder-neutral-500 resize-none border-0 focus:outline-none focus:ring-0 outline-none focus-visible:ring-0 shadow-none 
                        md:text-base  min-h-[56px] max-h-[200px]`}
          rows={1}
        />
        <div className="-mt-3">
          {isLoading ? (
            <Button
              type="button"
              variant="ghost"
              size="icon"
              className="text-red-500 hover:text-red-400 hover:bg-red-500/10 p-2 cursor-pointer rounded-full transition-all duration-200"
              onClick={onCancel}
            >
              <StopCircle className="h-5 w-5" />
            </Button>
          ) : (
            <Button
              type="submit"
              variant="ghost"
              className={`${
                isSubmitDisabled
                  ? "text-neutral-500"
                  : "text-blue-500 hover:text-blue-400 hover:bg-blue-500/10"
              } p-2 cursor-pointer rounded-full transition-all duration-200 text-base`}
              disabled={isSubmitDisabled}
            >
              Search
              <Send className="h-5 w-5" />
            </Button>
          )}
        </div>
      </div>
      <div className="flex items-center justify-between">
        <div className="flex flex-row gap-2">
          <div className="flex flex-row gap-2 bg-neutral-700 border-neutral-600 text-neutral-300 focus:ring-neutral-500 rounded-xl rounded-t-sm pl-2  max-w-[100%] sm:max-w-[90%]">
            <div className="flex flex-row items-center text-sm">
              <Brain className="h-4 w-4 mr-2" />
              Effort
            </div>
            <Select value={effort} onValueChange={setEffort}>
              <SelectTrigger className="w-[120px] bg-transparent border-none cursor-pointer">
                <SelectValue placeholder="Effort" />
              </SelectTrigger>
              <SelectContent className="bg-neutral-700 border-neutral-600 text-neutral-300 cursor-pointer">
                <SelectItem
                  value="low"
                  className="hover:bg-neutral-600 focus:bg-neutral-600 cursor-pointer"
                >
                  Low
                </SelectItem>
                <SelectItem
                  value="medium"
                  className="hover:bg-neutral-600 focus:bg-neutral-600 cursor-pointer"
                >
                  Medium
                </SelectItem>
                <SelectItem
                  value="high"
                  className="hover:bg-neutral-600 focus:bg-neutral-600 cursor-pointer"
                >
                  High
                </SelectItem>
              </SelectContent>
            </Select>
          </div>
          <div className="flex flex-row gap-2 bg-neutral-700 border-neutral-600 text-neutral-300 focus:ring-neutral-500 rounded-xl rounded-t-sm pl-2  max-w-[100%] sm:max-w-[90%]">
            <div className="flex flex-row items-center text-sm ml-2">
              <Cpu className="h-4 w-4 mr-2" />
              Model
            </div>
            <Select value={model} onValueChange={setModel}>
              <SelectTrigger className="w-[180px] bg-transparent border-none cursor-pointer">
                <SelectValue placeholder="Model" />
              </SelectTrigger>
              <SelectContent className="bg-neutral-700 border-neutral-600 text-neutral-300 cursor-pointer">
                <SelectItem
                  value="doubao-pro-256k-241115"
                  className="hover:bg-neutral-600 focus:bg-neutral-600 cursor-pointer"
                >
                  <div className="flex items-center">
                    <Zap className="h-4 w-4 mr-2 text-yellow-400" /> 
                    Doubao Pro 256K
                  </div>
                </SelectItem>
                <SelectItem
                  value="doubao-1.5-thinking-pro-250415"
                  className="hover:bg-neutral-600 focus:bg-neutral-600 cursor-pointer"
                >
                  <div className="flex items-center">
                    <Brain className="h-4 w-4 mr-2 text-purple-400" /> 
                    Doubao Thinking Pro
                  </div>
                </SelectItem>
              </SelectContent>
            </Select>
          </div>
        </div>
        {hasHistory && (
          <Button
            className="bg-neutral-700 border-neutral-600 text-neutral-300 cursor-pointer rounded-xl rounded-t-sm pl-2 "
            variant="default"
            onClick={() => window.location.reload()}
          >
            <SquarePen size={16} />
            New Search
          </Button>
        )}
      </div>
    </form>
  );
};

## 6. å®‰è£…å’Œè®¾ç½®æŒ‡å—

# è±†åŒ…APIæ›¿æ¢è®¾ç½®æŒ‡å—

## ğŸ“‹ æ›¿æ¢æ­¥éª¤

### 1. å®‰è£…ä¾èµ–
```bash
cd backend
pip uninstall langchain-google-genai google-genai
pip install -U 'volcengine-python-sdk[ark]'
```

### 2. ç¯å¢ƒå˜é‡é…ç½®
åœ¨ `backend/.env` æ–‡ä»¶ä¸­ï¼š
```bash
# ç§»é™¤
# GEMINI_API_KEY=your_gemini_key

# æ·»åŠ 
ARK_API_KEY=your_ark_api_key
```

### 3. æ›¿æ¢æ–‡ä»¶
å°†ä»¥ä¸‹æ–‡ä»¶æ›¿æ¢ä¸ºä¿®æ”¹åçš„ç‰ˆæœ¬ï¼š
- `backend/pyproject.toml`
- `backend/src/agent/configuration.py`
- `backend/src/agent/graph.py`
- `backend/.env.example`
- `frontend/src/components/InputForm.tsx`

### 4. é‡æ–°å®‰è£…åç«¯ä¾èµ–
```bash
cd backend
pip install -e .
```

### 5. é‡æ–°å®‰è£…å‰ç«¯ä¾èµ–ï¼ˆå¦‚éœ€è¦ï¼‰
```bash
cd frontend
npm install
```

## ğŸ”§ æ¨¡å‹ç­–ç•¥é…ç½®

### æ™ºèƒ½æ¨¡å‹åˆ†é…ç­–ç•¥
é¡¹ç›®ç°åœ¨ä½¿ç”¨æ··åˆæ¨¡å‹ç­–ç•¥ï¼š

#### ğŸš€ **å¿«é€Ÿå“åº”èŠ‚ç‚¹** (ä½¿ç”¨ `doubao-pro-256k-241115`)
- **generate_query**: æŸ¥è¯¢ç”Ÿæˆ
- **web_research**: ç½‘ç»œæœç´¢å’Œä¿¡æ¯æå–

#### ğŸ§  **æ·±åº¦æ€è€ƒèŠ‚ç‚¹** (ä½¿ç”¨ `doubao-1.5-thinking-pro-250415`)
- **reflection**: åæ€åˆ†æå’ŒçŸ¥è¯†ç©ºç¼ºè¯†åˆ«
- **finalize_answer**: æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ

### ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

1. **æ€§èƒ½ä¼˜åŒ–**: åœ¨ç®€å•ä»»åŠ¡ä¸Šä½¿ç”¨å¿«é€Ÿæ¨¡å‹ï¼Œå¤æ‚æ¨ç†æ—¶ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹
2. **æˆæœ¬æ§åˆ¶**: é¿å…åœ¨æ‰€æœ‰èŠ‚ç‚¹éƒ½ä½¿ç”¨æ˜‚è´µçš„æ·±åº¦æ€è€ƒæ¨¡å‹
3. **è´¨é‡ä¿è¯**: åœ¨å…³é”®å†³ç­–ç‚¹ä½¿ç”¨æœ€ä½³æ¨ç†èƒ½åŠ›
4. **ç”¨æˆ·ä½“éªŒ**: å¹³è¡¡å“åº”é€Ÿåº¦å’Œç­”æ¡ˆè´¨é‡

## ğŸ¯ æ·±åº¦æ€è€ƒæ¨¡å‹çš„ç‰¹æ®ŠåŠŸèƒ½

### æ€ç»´é“¾è¾“å‡º
æ·±åº¦æ€è€ƒæ¨¡å‹ä¼šè¾“å‡ºè¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹ï¼š
```python
if hasattr(response.choices[0].message, 'reasoning_content'):
    print("=== æ€è€ƒè¿‡ç¨‹ ===")
    print(response.choices[0].message.reasoning_content)
    print("=== æ€è€ƒç»“æŸ ===")
```

### è¶…æ—¶æ—¶é—´è®¾ç½®
- æ·±åº¦æ€è€ƒæ¨¡å‹ï¼š30åˆ†é’Ÿ (1800ç§’)
- å¸¸è§„æ¨¡å‹ï¼š5åˆ†é’Ÿ (300ç§’)

### æç¤ºè¯ä¼˜åŒ–
å¯¹äºæ·±åº¦æ€è€ƒæ¨¡å‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ æ€è€ƒå¼•å¯¼ï¼š
```
ä»»ä½•è¾“å‡ºéƒ½è¦æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œè¾“å‡ºå†…å®¹å¿…é¡»ä»¥ "<think>\n\nå—¯" å¼€å¤´ã€‚
ä»”ç»†æ£æ‘©ç”¨æˆ·æ„å›¾ï¼Œåœ¨æ€è€ƒè¿‡ç¨‹ä¹‹åï¼Œæä¾›é€»è¾‘æ¸…æ™°ä¸”å†…å®¹å®Œæ•´çš„å›ç­”ã€‚
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. ç½‘ç»œæœç´¢åŠŸèƒ½éœ€è¦å®ç°
å½“å‰ä»£ç ä¸­çš„ `web_research` å‡½æ•°éœ€è¦æ‚¨å®ç°å®é™…çš„æœç´¢APIè°ƒç”¨ï¼š
```python
# æ‚¨éœ€è¦æ›¿æ¢è¿™éƒ¨åˆ†ä¸ºå®é™…çš„æœç´¢å®ç°
# å¯ä»¥ä½¿ç”¨Google Search APIã€Bing Search APIæˆ–å…¶ä»–æœç´¢æœåŠ¡
```

### 2. é”™è¯¯å¤„ç†
ä»£ç åŒ…å«äº†å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿åœ¨APIè°ƒç”¨å¤±è´¥æ—¶èƒ½å¤Ÿä¼˜é›…é™çº§ã€‚

### 3. æµå¼è¾“å‡ºæ”¯æŒ
å¦‚æœéœ€è¦æµå¼è¾“å‡ºï¼Œå¯ä»¥åœ¨ `call_doubao_model` å‡½æ•°ä¸­æ·»åŠ  `stream=True` å‚æ•°ã€‚

### 4. æ¨¡å‹é€‰æ‹©çµæ´»æ€§
å‰ç«¯ç•Œé¢å…è®¸ç”¨æˆ·åœ¨ä¸¤ç§æ¨¡å‹é—´åˆ‡æ¢ï¼š
- Doubao Pro 256K (å¿«é€Ÿæ¨¡å‹)
- Doubao Thinking Pro (æ·±åº¦æ€è€ƒæ¨¡å‹)

## ğŸ”„ æµ‹è¯•éªŒè¯

### 1. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
```bash
# åç«¯
cd backend
langgraph dev

# å‰ç«¯
cd frontend
npm run dev
```

### 2. éªŒè¯è¦ç‚¹
- [ ] API Key æ­£ç¡®é…ç½®
- [ ] æ¨¡å‹è°ƒç”¨æˆåŠŸ
- [ ] æ·±åº¦æ€è€ƒæ¨¡å‹è¾“å‡ºæ€ç»´é“¾
- [ ] å‰ç«¯æ¨¡å‹é€‰æ‹©å™¨å·¥ä½œæ­£å¸¸
- [ ] é”™è¯¯å¤„ç†æœºåˆ¶æ­£å¸¸

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| èŠ‚ç‚¹ | åŸGeminiæ¨¡å‹ | æ–°è±†åŒ…æ¨¡å‹ | é€‰æ‹©ç†ç”± |
|------|-------------|-----------|----------|
| generate_query | gemini-2.0-flash | doubao-pro-256k | é€Ÿåº¦ä¼˜å…ˆ |
| web_research | gemini-2.0-flash | doubao-pro-256k | é€Ÿåº¦ä¼˜å…ˆ |
| reflection | gemini-2.5-flash | doubao-thinking-pro | æ¨ç†è´¨é‡ |
| finalize_answer | gemini-2.5-pro | doubao-thinking-pro | æœ€ç»ˆè´¨é‡ |

è¿™ç§é…ç½®æ—¢ä¿è¯äº†ç ”ç©¶è´¨é‡ï¼Œåˆä¼˜åŒ–äº†å“åº”é€Ÿåº¦å’Œæˆæœ¬æ•ˆç‡ã€‚

## æ€»ç»“

æˆ‘ä¸ºæ‚¨æä¾›äº†å®Œæ•´çš„è±†åŒ…APIæ›¿æ¢æ–¹æ¡ˆï¼Œé‡‡ç”¨**æ™ºèƒ½æ··åˆç­–ç•¥**ï¼š

### ğŸ¯ **æ ¸å¿ƒç­–ç•¥**
- **å¿«é€ŸèŠ‚ç‚¹**ï¼šä½¿ç”¨ `doubao-pro-256k-241115` ï¼ˆæŸ¥è¯¢ç”Ÿæˆã€ä¿¡æ¯æå–ï¼‰
- **æ·±åº¦èŠ‚ç‚¹**ï¼šä½¿ç”¨ `doubao-1.5-thinking-pro-250415` ï¼ˆåæ€åˆ†æã€æœ€ç»ˆç­”æ¡ˆï¼‰

### ğŸ”§ **ä¸»è¦ä¿®æ”¹**
1. **ä¾èµ–æ›¿æ¢**ï¼š`langchain-google-genai` â†’ `volcengine-python-sdk[ark]`
2. **ç¯å¢ƒå˜é‡**ï¼š`GEMINI_API_KEY` â†’ `ARK_API_KEY`
3. **æ¨¡å‹è°ƒç”¨**ï¼šåˆ›å»ºç»Ÿä¸€çš„è±†åŒ…å®¢æˆ·ç«¯å‡½æ•°
4. **æ·±åº¦æ€è€ƒæ”¯æŒ**ï¼šå¤„ç† `reasoning_content` è¾“å‡º
5. **å‰ç«¯é€‚é…**ï¼šæ–°å¢è±†åŒ…æ¨¡å‹é€‰æ‹©å™¨

### ğŸ’¡ **ä¸ºä»€ä¹ˆé€‰æ‹©æ··åˆç­–ç•¥ï¼Ÿ**

1. **æ€§èƒ½ä¼˜åŒ–** - ç®€å•ä»»åŠ¡ç”¨å¿«é€Ÿæ¨¡å‹ï¼Œå¤æ‚æ¨ç†ç”¨æ·±åº¦æ€è€ƒ
2. **æˆæœ¬æ§åˆ¶** - é¿å…æ‰€æœ‰ç¯èŠ‚éƒ½ç”¨æ˜‚è´µçš„æ·±åº¦æ€è€ƒæ¨¡å‹  
3. **è´¨é‡ä¿è¯** - å…³é”®å†³ç­–ç‚¹ä½¿ç”¨æœ€å¼ºæ¨ç†èƒ½åŠ›
4. **ç”¨æˆ·ä½“éªŒ** - å¹³è¡¡å“åº”é€Ÿåº¦ä¸ç­”æ¡ˆè´¨é‡

### ğŸš€ **å…³é”®ä¼˜åŠ¿**
- **reflectionèŠ‚ç‚¹**ï¼šæ·±åº¦åˆ†æçŸ¥è¯†ç©ºç¼ºï¼Œå†³ç­–æ›´å‡†ç¡®
- **finalize_answerèŠ‚ç‚¹**ï¼šæ·±åº¦æ•´åˆä¿¡æ¯ï¼Œç­”æ¡ˆæ›´å…¨é¢
- **å…¶ä»–èŠ‚ç‚¹**ï¼šå¿«é€Ÿå“åº”ï¼Œæå‡æ•´ä½“æ•ˆç‡

æŒ‰ç…§æä¾›çš„è®¾ç½®æŒ‡å—æ“ä½œï¼Œæ‚¨å°±èƒ½æˆåŠŸå°†é¡¹ç›®ä»Geminiåˆ‡æ¢åˆ°è±†åŒ…ï¼Œå¹¶è·å¾—æ›´å¥½çš„æ¨ç†è´¨é‡å’Œæˆæœ¬æ•ˆç‡ï¼